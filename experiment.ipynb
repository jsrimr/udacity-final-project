{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randint(0,3,(3,))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3009,  1.0515, -0.9211, -0.4472, -0.3552],\n",
       "        [-0.3797, -0.4905, -0.0278, -0.1023, -0.8494],\n",
       "        [-0.3797, -0.4905, -0.0278, -0.1023, -0.8494]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.7972, -0.6582,  0.1128,  0.6282, -0.4751],\n",
       "        [-0.3797, -0.4905, -0.0278, -0.1023, -0.8494],\n",
       "        [ 0.3009,  1.0515, -0.9211, -0.4472, -0.3552]], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PositionalEncoding(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000]],\n",
       "\n",
       "        [[ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.9563, -0.2925, -0.5121,  0.8589, -0.9737, -0.2278]],\n",
       "\n",
       "        [[ 0.2705, -0.9627, -0.4717,  0.8818, -0.9742, -0.2257]],\n",
       "\n",
       "        [[-0.6639, -0.7478, -0.4303,  0.9027, -0.9747, -0.2236]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe.pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohlcv = torch.tensor([\n",
    "    [\n",
    "        [28948.19,28997.16,28935.30,28991.01,143.661],\n",
    "        [28992.98,29045.93,28991.01,29035.18,256.280],\n",
    "        [29036.41,29036.97,28993.19,29016.23,102.675],\n",
    "        [29016.23,29023.87,28995.50,29002.92,85.762],\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        [49889.01,49959.00,49700.00,49915.86,3813.991],\n",
    "        [49915.87,50089.99,49823.33,49881.85,5582.806],\n",
    "        [49881.85,50158.96,49830.71,50000.14,6702.779],\n",
    "        [50000.92,50102.26,49921.17,50069.01,4582.944],\n",
    "\n",
    "    ]\n",
    "])\n",
    "ohlcv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.]) tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "norm = nn.BatchNorm1d(5)\n",
    "print(norm.running_mean, norm.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4152, 0.6089, 0.2121, 0.1288, 0.1309],\n",
       "        [0.4898, 0.9148, 0.1486, 0.4143, 0.7636],\n",
       "        [0.4525, 0.7619, 0.1804, 0.2716, 0.4473]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(2,5)\n",
    "t = torch.cat([t,t.mean(0,keepdim=True)])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2182, -1.2244,  1.2157, -1.2243, -1.2247],\n",
       "        [ 1.2182,  1.2244, -1.2157,  1.2243,  1.2247],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0453, 0.0762, 0.0180, 0.0272, 0.0447]) tensor([0.9001, 0.9023, 0.9001, 0.9020, 0.9100])\n"
     ]
    }
   ],
   "source": [
    "print(norm.running_mean, norm.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4525, 0.7619, 0.1804, 0.2716, 0.4473]) tensor([0.9037, 0.9153, 0.9032, 0.9143, 0.9316])\n"
     ]
    }
   ],
   "source": [
    "print(t.mean(dim=(0)), t.std(dim=(0))*norm.momentum + torch.ones_like(t.std(dim=(0)))*(1-norm.momentum) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2453,  0.3311,  1.3888,  0.0214, 12.3220],\n",
       "        [ 0.4453,  0.1311,  1.1888,  0.2214, 12.5219],\n",
       "        [ 0.3453,  0.2311,  1.2888,  0.1214, 12.4219]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t - t.mean(dim=(0))*norm.momentum)/ (norm.eps + t.std(dim=(0))/norm.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0186, 0.0621, 0.0453, 0.0549, 0.0520])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0048, -1.0027, -1.0042, -1.0019, -0.9576],\n",
       "         [-1.0005, -0.9981, -0.9988, -0.9977, -0.9147],\n",
       "         [-0.9964, -0.9989, -0.9986, -0.9995, -0.9732],\n",
       "         [-0.9983, -1.0002, -0.9984, -1.0008, -0.9796]],\n",
       "\n",
       "        [[ 0.9968,  0.9887,  0.9886,  0.9951,  0.4398],\n",
       "         [ 0.9994,  1.0012,  1.0004,  0.9919,  1.1132],\n",
       "         [ 0.9962,  1.0077,  1.0011,  1.0032,  1.5396],\n",
       "         [ 1.0075,  1.0023,  1.0098,  1.0098,  0.7325]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(ohlcv.transpose(1,2)).transpose(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([39460.1875, 39551.7656, 39398.7734, 39489.0234,  2658.8623])\n",
      "tensor([11184.1455, 11252.6826, 11139.6514, 11201.2656,  2807.9656])\n"
     ]
    }
   ],
   "source": [
    "print(ohlcv.mean(dim=(0,1)))\n",
    "print(ohlcv.std(dim=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[28948.1895, 28997.1602, 28935.3008, 28991.0098,   143.6610],\n",
       "         [28992.9805, 29045.9297, 28991.0098, 29035.1797,   256.2800],\n",
       "         [29036.4102, 29036.9707, 28993.1895, 29016.2305,   102.6750],\n",
       "         [29016.2305, 29023.8691, 28995.5000, 29002.9199,    85.7620]],\n",
       "\n",
       "        [[49889.0117, 49959.0000, 49700.0000, 49915.8594,  3813.9910],\n",
       "         [49915.8711, 50089.9883, 49823.3281, 49881.8516,  5582.8062],\n",
       "         [49881.8516, 50158.9609, 49830.7109, 50000.1406,  6702.7788],\n",
       "         [50000.9219, 50102.2617, 49921.1719, 50069.0117,  4582.9438]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohlcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9399, -0.9380, -0.9393, -0.9372, -0.8957],\n",
       "         [-0.9359, -0.9336, -0.9343, -0.9333, -0.8556],\n",
       "         [-0.9320, -0.9344, -0.9341, -0.9350, -0.9103],\n",
       "         [-0.9338, -0.9356, -0.9339, -0.9362, -0.9164]],\n",
       "\n",
       "        [[ 0.9325,  0.9249,  0.9247,  0.9309,  0.4114],\n",
       "         [ 0.9349,  0.9365,  0.9358,  0.9278,  1.0413],\n",
       "         [ 0.9318,  0.9426,  0.9365,  0.9384,  1.4402],\n",
       "         [ 0.9425,  0.9376,  0.9446,  0.9445,  0.6852]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ohlcv - ohlcv.mean(dim=(0,1)))/ (norm.eps + ohlcv.std(dim=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시가로 나눠주고, 거래량은 batch 단위로 나눠주자"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa19752063a99a8f5db2dacef7b22e2ec238927163830f1a9e70fe2782c164ec"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
